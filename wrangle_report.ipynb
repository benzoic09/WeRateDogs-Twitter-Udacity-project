{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this report, I will describe my wrangling efforts for the Udacity data wrangling project. The data for this project was sourced from the WeRateDogs Twitter account, which rates dogs and provides humorous commentary on the ratings. The data consisted of three different sources:\n",
    "\n",
    "1. A twitter archive file that contained basic information about tweets such as tweet ID, timestamp, and text.\n",
    "\n",
    "2. A file of image predictions that contained predictions of what was in the images of tweets, such as dog breeds.\n",
    "\n",
    "3. Additional data that was gathered via the Twitter API, such as the number of retweets and favorites for each tweet.\n",
    "\n",
    "My first step in the wrangling process was to assess the data for quality and tidiness issues. I found several issues in the data, including:\n",
    "\n",
    "Missing data in the image predictions file and additional data from the Twitter API.\n",
    "\n",
    "Incorrect data types for some columns, such as the timestamp column being a string rather than a datetime object.\n",
    "\n",
    "Inaccurate dog ratings in the text column, as some ratings were not in the format of \"x/10\".\n",
    "\n",
    "Inconsistencies in the dog breed predictions, as some predictions were not the name of a breed, but rather a phrase such as \"not a dog\".\n",
    "\n",
    "To address these issues, I performed a series of cleaning actions. For missing data, I dropped the rows that had missing values in the image predictions file and additional data from the Twitter API. For incorrect data types, I converted the timestamp column to a datetime object. To handle inaccurate dog ratings, I extracted the rating numerator and denominator from the text column and created new columns for them, then I dropped the text column. And to fix the breed predictions I replaced it with a breed if the breed has a high confidence or if not I put not a dog or other.\n",
    "\n",
    "Next, I tackled the tidiness issues in the data. The main tidiness issue I found was that the dog \"stage\" (e.g. \"pupper\", \"doggo\") was spread across multiple columns in the twitter archive file. To fix this, I created a new column called \"stage\" and consolidated the information from the other columns into it.\n",
    "\n",
    "Finally, I exported the cleaned data to a new csv file for further analysis.\n",
    "\n",
    "Overall, the wrangling process for this project was challenging, but it allowed me to gain a deeper understanding of the data and improve its quality and tidiness. Through the cleaning process I was able to remove unnecessary columns and data, fix inaccuracies, and make the data more usable for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
